{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "\n",
    "from batchgenerators.dataloading.data_loader import DataLoaderBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create a DataLoader that gives us some image. Your implementation will vary depending on your dataset. Here we just output the same image all the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(DataLoaderBase):\n",
    "    def __init__(self, data, BATCH_SIZE=2, num_batches=None, seed=False):\n",
    "        super(DataLoader, self).__init__(data, BATCH_SIZE, num_batches, seed) \n",
    "        # data is now stored in self._data.\n",
    "    \n",
    "    def generate_train_batch(self):\n",
    "        # usually you would now select random instances of your data. We only have one therefore we skip this\n",
    "        img = self._data\n",
    "        \n",
    "        # The camera image has only one channel. Our batch layout must be (b, c, x, y). Let's fix that\n",
    "        img = np.tile(img[None, None], (self.BATCH_SIZE, 1, 1, 1))\n",
    "        \n",
    "        # now construct the dictionary and return it. np.float32 cast because most networks take float\n",
    "        return {'data':img.astype(np.float32), 'some_other_key':'some other value'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can get some batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchgen = DataLoader(data.camera(), 4, None, False)\n",
    "batch = next(batchgen)\n",
    "\n",
    "def plot_batch(batch):\n",
    "    batch_size = batch['data'].shape[0]\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    for i in range(batch_size):\n",
    "        plt.subplot(1, batch_size, i+1)\n",
    "        plt.imshow(batch['data'][i, 0], cmap=\"gray\") # only grayscale image here\n",
    "    plt.show()\n",
    "\n",
    "plot_batch(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's time for some transformations! \n",
    "We are not going to waste any time and do it multithreaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batchgenerators.transforms.color_transforms import ContrastAugmentationTransform\n",
    "from batchgenerators.transforms.spatial_transforms import Mirror\n",
    "from batchgenerators.transforms.abstract_transforms import Compose\n",
    "from batchgenerators.dataloading.multi_threaded_augmenter import MultiThreadedAugmenter\n",
    "\n",
    "my_transforms = []\n",
    "brightness_transform = ContrastAugmentationTransform((0.3, 3.), preserve_range=True)\n",
    "my_transforms.append(brightness_transform)\n",
    "mirror_transform = Mirror(axes=(2, 3))\n",
    "my_transforms.append(mirror_transform)\n",
    "\n",
    "all_transforms = Compose(my_transforms)\n",
    "multithreaded_generator = MultiThreadedAugmenter(batchgen, all_transforms, 4, 2, seeds=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can run this line several times to see different outputs\n",
    "plot_batch(multithreaded_generator.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multithreaded_generator._finish() # kill the workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets add some deformations, scaling and rotations. \n",
    "We use very aggressive parameters here to visualize the effects. In your experiment you should choose parameters that make sense in the context of your data.\n",
    "Not how we are using angle_z here. We are rotating around the (nonexistent) z axis. Always double check whether the rotations are around the correct axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batchgenerators.transforms.spatial_transforms import SpatialTransform\n",
    "\n",
    "spatial_transform = SpatialTransform(data.camera().shape, np.array(data.camera().shape) // 2, \n",
    "                 do_elastic_deform=True, alpha=(0., 1500.), sigma=(30., 50.),\n",
    "                 do_rotation=True, angle_z=(0, 2 * np.pi),\n",
    "                 do_scale=True, scale=(0.3, 3.), \n",
    "                 border_mode_data='constant', border_cval_data=0, order_data=1,\n",
    "                 random_crop=False)\n",
    "\n",
    "my_transforms.append(spatial_transform)\n",
    "all_transforms = Compose(my_transforms)\n",
    "multithreaded_generator = MultiThreadedAugmenter(batchgen, all_transforms, 4, 2, seeds=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can run this line several times to see different outputs. Note how the computation takes long for the \n",
    "# first run, but then the batches are returnes very quickly!\n",
    "plot_batch(next(multithreaded_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do some timing\n",
    "from time import time\n",
    "\n",
    "batch_times = []\n",
    "multithreaded_generator = MultiThreadedAugmenter(batchgen, all_transforms, 4, 2, seeds=None)\n",
    "for _ in range(20):\n",
    "    start = time()\n",
    "    _ = next(multithreaded_generator)\n",
    "    batch_times.append(time() - start)\n",
    "    print(\"This batch took %02.3f s\" % batch_times[-1])\n",
    "\n",
    "avg_batch_time_mt = np.mean(batch_times)\n",
    "print(\"Multi threaded batch generation using 4 workers took %02.3f s on average per batch\" % avg_batch_time_mt)\n",
    "\n",
    "\n",
    "batch_times = []\n",
    "multithreaded_generator = MultiThreadedAugmenter(batchgen, all_transforms, 1, 2, seeds=None)\n",
    "for _ in range(20):\n",
    "    start = time()\n",
    "    _ = next(multithreaded_generator)\n",
    "    batch_times.append(time() - start)\n",
    "    print(\"This batch took %02.3f s\" % batch_times[-1])\n",
    "\n",
    "avg_batch_time_st = np.mean(batch_times)\n",
    "print(\"Single threaded batch generation using 4 workers took %02.3f s on average per batch\" % avg_batch_time_st)\n",
    "\n",
    "print(\"Multi threaded speedup: %02.2f\" % (avg_batch_time_st/avg_batch_time_mt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sometimes you don't want to apply a transformation to every batch. We've got you covered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batchgenerators.transforms.abstract_transforms import RndTransform\n",
    "\n",
    "sometimes_spatial_transform = RndTransform(spatial_transform, prob=0.5)\n",
    "multithreaded_generator = MultiThreadedAugmenter(batchgen, Compose([sometimes_spatial_transform]), 4, 2, seeds=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(4):\n",
    "    plot_batch(next(multithreaded_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping\n",
    "\n",
    "Usually when you train you need an input patch of a specific size. This is especially true for some segementation problems. If you are NOT using the SpatialTransform then just use the RandomCropTransform or CenterCropTransform. Your DataLoader can in this case return an arbitrarily sized image and you can crontrol the size with those (what is most efficient depends on how your dataset is implemented. I am using numpy memmaps and therefore always return the full size). If you are using SpatialTransform then you can use it to crop your data at the same time they are transformed. “But wait - will transforming a large image not be super slow”? No, because the way SpatialTransform works is that is creates a coordinate grid that is transformed and in the end the data is interpolated along that grid. The computation time therefore depends only on the output patch size. Also, if you have a 128x128 patch that you then transform spatially, you will get border artifacts. If you instead plug the entire image into the SpatialTransform and tell it to extract a 128x128 patch then you can avoid these artifacts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial augmentation with small patches, crop first then transform (do not do this)\n",
    "from batchgenerators.transforms.crop_and_pad_transforms import RandomCropTransform\n",
    "crop_size = (128, 128)\n",
    "\n",
    "batchgen = DataLoader(data.camera(), 4, None, False)\n",
    "\n",
    "crop = RandomCropTransform(crop_size=crop_size)\n",
    "spatial_transform = SpatialTransform(crop_size, np.array(crop_size) // 2, \n",
    "                 do_elastic_deform=True, alpha=(0., 1500.), sigma=(30., 50.),\n",
    "                 do_rotation=True, angle_z=(0, 2 * np.pi),\n",
    "                 do_scale=True, scale=(0.5, 2),\n",
    "                 border_mode_data='constant', border_cval_data=0, order_data=1,\n",
    "                 random_crop=False)\n",
    "multithreaded_generator = MultiThreadedAugmenter(batchgen, Compose([crop, spatial_transform]), 4, 2, seeds=None)\n",
    "\n",
    "# time it\n",
    "start = time()\n",
    "for _ in range(100):\n",
    "    _ = next(multithreaded_generator)\n",
    "print(\"Crop followed by SpatialTransform (20 batches) took: %02.3f s\" % (time()-start))\n",
    "\n",
    "plot_batch(next(multithreaded_generator))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# spatial augmentation with snall patches, transform and crop together (do this!)\n",
    "spatial_transform = SpatialTransform(crop_size, np.array(crop_size) // 2,\n",
    "                 do_elastic_deform=True, alpha=(0., 1500.), sigma=(30., 50.),\n",
    "                 do_rotation=True, angle_z=(0, 2 * np.pi),\n",
    "                 do_scale=True, scale=(0.5, 2),\n",
    "                 border_mode_data='constant', border_cval_data=0, order_data=1,\n",
    "                 random_crop=True)\n",
    "multithreaded_generator = MultiThreadedAugmenter(batchgen, Compose([spatial_transform]), 4, 2, seeds=None)\n",
    "\n",
    "# time it\n",
    "start = time()\n",
    "for _ in range(100):\n",
    "    _ = next(multithreaded_generator)\n",
    "print(\"Crop integrated into SpatialTransform (20 batches) took: %02.3f s\" % (time()-start))\n",
    "\n",
    "plot_batch(next(multithreaded_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see you are much less likely to get border artifacts when using the second option. Output is in each case a batch with size 128x128 pixels and computation time is the same!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batchgenerators.transforms.noise_transforms import RicianNoiseTransform\n",
    "from batchgenerators.dataloading.multi_threaded_augmenter import MultiThreadedAugmenter\n",
    "\n",
    "noise_transform = RicianNoiseTransform(noise_variance=(0, 200))\n",
    "multithreaded_generator = MultiThreadedAugmenter(batchgen, noise_transform, 4, 2, seeds=None)\n",
    "\n",
    "# you can run this line several times to see different outputs\n",
    "plot_batch(next(multithreaded_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batchgenerators.transforms.resample_transforms import ResampleTransform\n",
    "from batchgenerators.dataloading.multi_threaded_augmenter import MultiThreadedAugmenter\n",
    "\n",
    "resample_transform = ResampleTransform(zoom_range=(0.05, 0.2))\n",
    "multithreaded_generator = MultiThreadedAugmenter(batchgen, resample_transform, 1, 2, seeds=None)\n",
    "\n",
    "# you can run this line several times to see different outputs\n",
    "plot_batch(next(multithreaded_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We hope this tutorial helped. For suggestions please contact us ;-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (envGUT)",
   "language": "python",
   "name": "envgut"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

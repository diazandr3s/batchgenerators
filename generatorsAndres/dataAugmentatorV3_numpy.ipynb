{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import itk\n",
    "import os\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_files(base_dir):\n",
    "\n",
    "    list_of_lists = []\n",
    "    patients = os.listdir(base_dir)\n",
    "    for p in patients:\n",
    "        if p.startswith(\"mr_train_\") and p.endswith(\".nii.gz\"):\n",
    "            list_of_lists.append(os.path.join(base_dir, p))\n",
    "    print(\"Found %d patients\" % len(list_of_lists))\n",
    "    return list_of_lists\n",
    "\n",
    "\n",
    "def load_img(dir_img):\n",
    "    # load SimpleITK Image\n",
    "    img_sitk = sitk.ReadImage(dir_img)\n",
    "\n",
    "    # get pixel arrays from SimpleITK images\n",
    "    img_npy = sitk.GetArrayFromImage(img_sitk)\n",
    "\n",
    "    # get some metadata\n",
    "    spacing = img_sitk.GetSpacing()\n",
    "    # the spacing returned by SimpleITK is in inverse order relative to the numpy array we receive. If we wanted to\n",
    "    # resample the data and if the spacing was not isotropic (in BraTS all cases have already been resampled to 1x1x1mm\n",
    "    # by the organizers) then we need to pay attention here. Therefore we bring the spacing into the correct order so\n",
    "    # that spacing[0] actually corresponds to the spacing of the first axis of the numpy array\n",
    "    spacing = np.array(spacing)[::-1]\n",
    "    direction = img_sitk.GetDirection()\n",
    "    origin = img_sitk.GetOrigin()\n",
    "\n",
    "    original_shape = img_npy.shape\n",
    "    \n",
    "    metadata = {\n",
    "    'spacing': spacing,\n",
    "    'direction': direction,\n",
    "    'origin': origin,\n",
    "    'original_shape': original_shape\n",
    "    }\n",
    "        \n",
    "    print(\"Pixel Type    {}\".format(img_sitk.GetPixelID()))\n",
    "    print(\"Size          {}\".format(img_sitk.GetSize()))\n",
    "    print(\"Origin        {}\".format(origin))\n",
    "    print(\"Spacing       {}\".format(spacing))\n",
    "    print(\"Direction     {}\".format(direction))    \n",
    "    \n",
    "    return img_sitk, img_npy, metadata  \n",
    "\n",
    "\n",
    "\n",
    "def get_center(img):\n",
    "    \"\"\"\n",
    "    This function returns the physical center point of a 3d sitk image\n",
    "    :param img: The sitk image we are trying to find the center of\n",
    "    :return: The physical center point of the image\n",
    "    \"\"\"\n",
    "    width, height, depth = img.GetSize()\n",
    "    \n",
    "    return img.TransformIndexToPhysicalPoint((int(np.ceil(width/2)),\n",
    "                                          int(np.ceil(height/2)),\n",
    "                                          int(np.ceil(depth/2))))\n",
    "\n",
    "\n",
    "def rotate_img(img_sitk, transform, is_label, theta_x, theta_y, theta_z):\n",
    "    \n",
    "#     new_transform = sitk.AffineTransform(transform)\n",
    "#     matrix = np.array(transform.GetMatrix()).reshape((3,3))\n",
    "#     radians = -np.pi * theta_x / 180.\n",
    "#     rotation = np.array([[np.sin(radians), np.cos(radians), 0], \n",
    "#                         [0, 0, 1],\n",
    "#                         [np.cos(radians), -np.sin(radians), 0]] )  # https://stackoverflow.com/questions/9187387/3d-rotation-on-image\n",
    "#     new_matrix = np.dot(rotation, matrix)\n",
    "#     new_transform.SetMatrix(new_matrix.ravel())\n",
    "    \n",
    "    theta_x = np.deg2rad(theta_x)\n",
    "    theta_y = np.deg2rad(theta_y)\n",
    "    theta_z = np.deg2rad(theta_z)\n",
    "    \n",
    "    new_transform = sitk.Euler3DTransform(get_center(img_sitk), theta_x, theta_y, theta_z, (0, 0, 0))\n",
    "    image_center = get_center(img_sitk)\n",
    "    new_transform.SetCenter(image_center)\n",
    "    new_transform.SetRotation(theta_x, theta_y, theta_z)  \n",
    "    \n",
    "    # Resample\n",
    "    reference_image = img_sitk\n",
    "    \n",
    "    if is_label:\n",
    "        interpolator = sitk.sitkNearestNeighbor\n",
    "    else:\n",
    "        interpolator = sitk.sitkBSpline # sitkCosineWindowedSinc    \n",
    "\n",
    "    default_value = 0\n",
    "    resampled = sitk.Resample(img_sitk, reference_image, new_transform,\n",
    "                         interpolator, default_value)  \n",
    "    npy_img = sitk.GetArrayFromImage(resampled)\n",
    "    \n",
    "    return npy_img, resampled\n",
    "\n",
    "\n",
    "def reorient_to_rai(image):\n",
    "    filter = itk.OrientImageFilter.New(image)\n",
    "    filter.UseImageDirectionOn()\n",
    "    filter.SetInput(image)\n",
    "    m = itk.Matrix[itk.D, 3, 3]()\n",
    "    m.SetIdentity()\n",
    "    filter.SetDesiredCoordinateDirection(m)\n",
    "    filter.Update()\n",
    "    return filter.GetOutput()\n",
    "\n",
    "\n",
    "def save_as_nii(img_npy, img_name, metadata):\n",
    "    sitk_image = sitk.GetImageFromArray(img_npy)\n",
    "    sitk_image.SetDirection(metadata['direction'])\n",
    "    sitk_image.SetOrigin(metadata['origin'])\n",
    "    # remember to revert spacing back to sitk order again\n",
    "    sitk_image.SetSpacing(tuple(metadata['spacing'][[1, 2, 0]]))\n",
    "    sitk.WriteImage(sitk_image, img_name)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 patients\n",
      "/usr/not-backed-up2/scsad/DL/MedicalDataAugmentationTool/bin/experiments/semantic_segmentation/mmwhs/TODO_mr/mr_train_1020_image.nii.gz\n",
      "/usr/not-backed-up2/scsad/DL/MedicalDataAugmentationTool/bin/experiments/semantic_segmentation/mmwhs/TODO_mr/mr_train_1020_label.nii.gz\n"
     ]
    }
   ],
   "source": [
    "base_dir = '/usr/not-backed-up2/scsad/DL/MedicalDataAugmentationTool/bin/experiments/semantic_segmentation/mmwhs/TODO_mr'\n",
    "list_of_files = get_list_of_files(base_dir)\n",
    "dir_img = list_of_files[38]\n",
    "dir_label = list_of_files[39]\n",
    "print(dir_img)\n",
    "print(dir_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel Type    2\n",
      "Size          (288, 288, 135)\n",
      "Origin        (134.70086669921875, -172.93592834472656, -103.38882446289062)\n",
      "Spacing       [1.04999995 0.97222221 0.97222221]\n",
      "Direction     (-0.0, 0.0, -1.0, 1.0, -0.0, 0.0, 0.0, 1.0, -0.0)\n",
      "Pixel Type    3\n",
      "Size          (288, 288, 135)\n",
      "Origin        (134.70086669921875, -172.93592834472656, -103.38882446289062)\n",
      "Spacing       [1.04999995 0.97222221 0.97222221]\n",
      "Direction     (-0.0, 0.0, -1.0, 1.0, -0.0, 0.0, 0.0, 1.0, -0.0)\n"
     ]
    }
   ],
   "source": [
    "img_sitk, img_npy, metadata_img = load_img(dir_img)\n",
    "label_sitk, label_npy, metadata_label = load_img(dir_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate image\n",
    "theta_x, theta_y, theta_z = 0, 30, 0\n",
    "affine_ro = sitk.AffineTransform(3)\n",
    "npy_rotated, rotated_image = rotate_img(img_sitk, affine_ro, False, theta_x, theta_y, theta_z) # https://stackoverflow.com/questions/56171643/simpleitk-rotation-of-mri-image\n",
    "#reorientedToRAI = reorient_to_rai(rotated_image)\n",
    "sitk.WriteImage(rotated_image, 'rotation_X' + str(theta_x) + 'Y' + str(theta_y) + 'Z' + str(theta_z) + '_' + dir_img.split('/')[11:][0][0:-7] + '.nii.gz', True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate label\n",
    "affine_ro = sitk.AffineTransform(3)\n",
    "npy_rotated_label, rotated_label = rotate_img(label_sitk, affine_ro, True, theta_x, theta_y, theta_z) \n",
    "#reorientedToRAI_label = reorient_to_rai(rotated_label)\n",
    "sitk.WriteImage(rotated_label, 'rotation_X' + str(theta_x) + 'Y' + str(theta_y) + 'Z' + str(theta_z) + '_' + dir_img.split('/')[11:][0][0:-7] + '.nii.gz', True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 288, 288)\n",
      "[1.04999995 0.97222221 0.97222221]\n"
     ]
    }
   ],
   "source": [
    "# Downsampling image. \n",
    "\n",
    "# Check how to reorient the image to RAI and then downsample it to only 16 slices!\n",
    "# Do the same for the label!\n",
    "\n",
    "downsampled_img = np.array([npy_rotated[i*10,:,:] for i in range(0, 13)],dtype=np.float32)\n",
    "    \n",
    "print(downsampled_img.shape)   \n",
    "print(metadata_img['spacing'])\n",
    "save_as_nii(downsampled_img, 'downsample.nii.gz', metadata_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling label \n",
    "\n",
    "downsampled_label = np.array([npy_rotated_label[i*10,:,:] for i in range(0, 13)],dtype=np.float32)\n",
    "save_as_nii(downsampled_label, 'downsample_label.nii.gz', metadata_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_npy.shape)\n",
    "print(label_npy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    idx = i*2+65\n",
    "    plt.imshow(rotated_image[:,idx,:].T, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to have the max resolution of these images in sagital view\n",
    "# As the sagital view we have from Deaglan images are sagital view with slight inclination,\n",
    "# we could first rotate training images to have them very similar to SPASM images\n",
    "\n",
    "\n",
    "# To do this, we need to inclinate the images from the sagital view.\n",
    "# Take the sagital view images that cover the whole heart\n",
    "\n",
    "# To rescale images: https://scikit-image.org/docs/dev/auto_examples/transform/plot_rescale.html\n",
    "\n",
    "# How can we expand the physical space??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (envGUT)",
   "language": "python",
   "name": "envgut"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import itk\n",
    "import os\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 patients\n",
      "/usr/not-backed-up2/scsad/DL/MedicalDataAugmentationTool/bin/experiments/semantic_segmentation/mmwhs/TODO_mr/mr_train_1020_image.nii.gz\n"
     ]
    }
   ],
   "source": [
    "def get_list_of_files(base_dir):\n",
    "\n",
    "    list_of_lists = []\n",
    "    patients = os.listdir(base_dir)\n",
    "    for p in patients:\n",
    "        if p.startswith(\"mr_train_\") and p.endswith(\"_image.nii.gz\"):\n",
    "            list_of_lists.append(os.path.join(base_dir, p))\n",
    "    print(\"Found %d patients\" % len(list_of_lists))\n",
    "    return list_of_lists\n",
    "\n",
    "base_dir = '/usr/not-backed-up2/scsad/DL/MedicalDataAugmentationTool/bin/experiments/semantic_segmentation/mmwhs/TODO_mr'\n",
    "list_of_files = get_list_of_files(base_dir)\n",
    "dir_img = list_of_files[19]\n",
    "print(dir_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel Type    2\n",
      "Size          (288, 288, 135)\n",
      "Origin        (134.70086669921875, -172.93592834472656, -103.38882446289062)\n",
      "Spacing       (0.9722222089767456, 0.9722222089767456, 1.0499999523162842)\n",
      "Direction     (-0.0, 0.0, -1.0, 1.0, -0.0, 0.0, 0.0, 1.0, -0.0)\n"
     ]
    }
   ],
   "source": [
    "def load_img(dir_img):\n",
    "    # load SimpleITK Image\n",
    "    img_sitk = sitk.ReadImage(dir_img)\n",
    "    \n",
    "    print(\"Pixel Type    {}\".format(img_sitk.GetPixelID()))\n",
    "    print(\"Size          {}\".format(img_sitk.GetSize()))\n",
    "    print(\"Origin        {}\".format(img_sitk.GetOrigin()))\n",
    "    print(\"Spacing       {}\".format(img_sitk.GetSpacing()))\n",
    "    print(\"Direction     {}\".format(img_sitk.GetDirection()))\n",
    "\n",
    "    # get pixel arrays from SimpleITK images\n",
    "    img_npy = sitk.GetArrayFromImage(img_sitk)\n",
    "\n",
    "    # get some metadata\n",
    "    spacing = img_sitk.GetSpacing()\n",
    "    # the spacing returned by SimpleITK is in inverse order relative to the numpy array we receive. If we wanted to\n",
    "    # resample the data and if the spacing was not isotropic (in BraTS all cases have already been resampled to 1x1x1mm\n",
    "    # by the organizers) then we need to pay attention here. Therefore we bring the spacing into the correct order so\n",
    "    # that spacing[0] actually corresponds to the spacing of the first axis of the numpy array\n",
    "    spacing = np.array(spacing)[::-1]\n",
    "    direction = img_sitk.GetDirection()\n",
    "    origin = img_sitk.GetOrigin()\n",
    "\n",
    "    original_shape = img_npy.shape\n",
    "    \n",
    "    metadata = {\n",
    "    'spacing': spacing,\n",
    "    'direction': direction,\n",
    "    'origin': origin,\n",
    "    'original_shape': original_shape\n",
    "    }\n",
    "    \n",
    "    return img_sitk, img_npy, metadata  \n",
    "\n",
    "\n",
    "img_sitk, img_npy, metadata = load_img(dir_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(image, transform):\n",
    "    # Output image Origin, Spacing, Size, Direction are taken from the reference\n",
    "    # image in this call to Resample\n",
    "    reference_image = image\n",
    "    interpolator = sitk.sitkCosineWindowedSinc\n",
    "    default_value = 100.0\n",
    "    return sitk.Resample(image, reference_image, transform,\n",
    "                         interpolator, default_value)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 1. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Rotation working!. Check how to avoid the labels to be distorted!!\n",
    "\n",
    "\n",
    "def affine_rotate(transform, degrees=45.0):\n",
    "    new_transform = sitk.AffineTransform(transform)\n",
    "    print(np.array(transform.GetMatrix()))\n",
    "    matrix = np.array(transform.GetMatrix()).reshape((3,3))\n",
    "    radians = -np.pi * degrees / 180.\n",
    "    rotation = np.array([[np.cos(radians), -np.sin(radians), 0], \n",
    "                         [np.sin(radians), np.cos(radians), 0], \n",
    "                         [0, 0, 1]])  # https://stackoverflow.com/questions/9187387/3d-rotation-on-image\n",
    "    new_matrix = np.dot(rotation, matrix)\n",
    "    new_transform.SetMatrix(new_matrix.ravel())\n",
    "    resampled = resample(img_sitk, new_transform)\n",
    "    return resampled\n",
    "    \n",
    "\n",
    "affine_ro = sitk.AffineTransform(3)\n",
    "rotated = affine_rotate(affine_ro)\n",
    "sitk.WriteImage(rotated, 'affine_rotation_' + list_of_files[19].split('/')[11:][0][0:-7] + '.nii.gz', True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9,)\n"
     ]
    }
   ],
   "source": [
    "def affine_scale(transform, x_scale=0.8, y_scale=0.7):\n",
    "    new_transform = sitk.AffineTransform(transform)\n",
    "    matrix = np.array(transform.GetMatrix()).reshape((3,3))\n",
    "    matrix[0,0] = x_scale\n",
    "    matrix[1,1] = y_scale\n",
    "    new_transform.SetMatrix(matrix.ravel())\n",
    "    resampled = resample(img_sitk, new_transform)\n",
    "    return resampled \n",
    "\n",
    "affine_sca = sitk.AffineTransform(3)\n",
    "scaled = affine_scale(affine_sca)\n",
    "sitk.WriteImage(scaled, 'affine_scaling_' + list_of_files[19].split('/')[11:][0][0:-7] + '.nii.gz', True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, the mechanics for image tranformations is to first create the affineTransform, \n",
    "# set the matrix to the tranformation and then resample!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 3\n",
    "\n",
    "# Physical image size corresponds to the largest physical size in the training set, or any other arbitrary size.\n",
    "reference_physical_size = np.zeros(dimension)\n",
    "\n",
    "# Create the reference image with a zero origin, identity direction cosine matrix and dimension     \n",
    "reference_origin = np.zeros(dimension)\n",
    "reference_direction = np.identity(dimension).flatten()\n",
    "\n",
    "# Select arbitrary number of pixels per dimension, smallest size that yields desired results \n",
    "# or the required size of a pretrained network (e.g. VGG-16 224x224), transfer learning. This will \n",
    "# often result in non-isotropic pixel spacing.\n",
    "reference_size = [128]*dimension \n",
    "reference_spacing = [ 1, 1, 1 ]\n",
    "\n",
    "# Another possibility is that you want isotropic pixels, then you can specify the image size for one of\n",
    "# the axes and the others are determined by this choice. Below we choose to set the x axis to 128 and the\n",
    "# spacing set accordingly. \n",
    "# Uncomment the following lines to use this strategy.\n",
    "#reference_size_x = 128\n",
    "#reference_spacing = [reference_physical_size[0]/(reference_size_x-1)]*dimension\n",
    "#reference_size = [int(phys_sz/(spc) + 1) for phys_sz,spc in zip(reference_physical_size, reference_spacing)]\n",
    "\n",
    "reference_image = sitk.Image(reference_size, 2)\n",
    "reference_image.SetOrigin(reference_origin)\n",
    "reference_image.SetSpacing(reference_spacing)\n",
    "reference_image.SetDirection(reference_direction)\n",
    "\n",
    "# Always use the TransformContinuousIndexToPhysicalPoint to compute an indexed point's physical coordinates as \n",
    "# this takes into account size, spacing and direction cosines. For the vast majority of images the direction \n",
    "# cosines are the identity matrix, but when this isn't the case simply multiplying the central index by the \n",
    "# spacing will not yield the correct coordinates resulting in a long debugging session. \n",
    "reference_center = np.array(reference_image.TransformContinuousIndexToPhysicalPoint(np.array(reference_image.GetSize())/2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_images_spatial(original_image, reference_image, T0, T_aug, transformation_parameters,\n",
    "                    output_prefix, output_suffix,\n",
    "                    interpolator = sitk.sitkLinear, default_intensity_value = 0.0):\n",
    "    '''\n",
    "    Generate the resampled images based on the given transformations.\n",
    "    Args:\n",
    "        original_image (SimpleITK image): The image which we will resample and transform.\n",
    "        reference_image (SimpleITK image): The image onto which we will resample.\n",
    "        T0 (SimpleITK transform): Transformation which maps points from the reference image coordinate system \n",
    "            to the original_image coordinate system.\n",
    "        T_aug (SimpleITK transform): Map points from the reference_image coordinate system back onto itself using the\n",
    "               given transformation_parameters. The reason we use this transformation as a parameter\n",
    "               is to allow the user to set its center of rotation to something other than zero.\n",
    "        transformation_parameters (List of lists): parameter values which we use T_aug.SetParameters().\n",
    "        output_prefix (string): output file name prefix (file name: output_prefix_p1_p2_..pn_.output_suffix).\n",
    "        output_suffix (string): output file name suffix (file name: output_prefix_p1_p2_..pn_.output_suffix).\n",
    "        interpolator: One of the SimpleITK interpolators.\n",
    "        default_intensity_value: The value to return if a point is mapped outside the original_image domain.\n",
    "    '''\n",
    "    all_images = [] # Used only for display purposes in this notebook.\n",
    "    for current_parameters in transformation_parameters:\n",
    "        T_aug.SetParameters(current_parameters)        \n",
    "        # Augmentation is done in the reference image space, so we first map the points from the reference image space\n",
    "        # back onto itself T_aug (e.g. rotate the reference image) and then we map to the original image space T0.\n",
    "        T_all = sitk.Transform(T0)\n",
    "        T_all.AddTransform(T_aug)\n",
    "        aug_image = sitk.Resample(original_image, reference_image, T_all,\n",
    "                                  interpolator, default_intensity_value)\n",
    "        sitk.WriteImage(aug_image, output_prefix + '_' + \n",
    "                        '_'.join(str(param) for param in current_parameters) +'_.' + output_suffix)\n",
    "         \n",
    "        all_images.append(aug_image) # Used only for display purposes in this notebook.\n",
    "    return all_images # Used only for display purposes in this notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-06750a76c237>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m generated_image = augment_images_spatial(img_sitk, reference_image, centered_transform, \n\u001b[1;32m     29\u001b[0m                                        \u001b[0maug_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformation_parameters_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                                        os.path.join('./', 'spatial_aug_'), 'mha')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-49f6b19721ae>\u001b[0m in \u001b[0;36maugment_images_spatial\u001b[0;34m(original_image, reference_image, T0, T_aug, transformation_parameters, output_prefix, output_suffix, interpolator, default_intensity_value)\u001b[0m\n\u001b[1;32m     28\u001b[0m                                   interpolator, default_intensity_value)\n\u001b[1;32m     29\u001b[0m         sitk.WriteImage(aug_image, output_prefix + '_' + \n\u001b[0;32m---> 30\u001b[0;31m                         '_'.join(str(param) for param in current_parameters) +'_.' + output_suffix)\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mall_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug_image\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Used only for display purposes in this notebook.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from utilities import parameter_space_regular_grid_sampling, \\\n",
    "                      similarity3D_parameter_space_regular_sampling, eul2quat \n",
    "\n",
    "\n",
    "transformation_parameters_list = similarity3D_parameter_space_regular_sampling(np.linspace(-np.pi/18.0,np.pi/18.0,3),\n",
    "                                                                               np.linspace(-np.pi/18.0,np.pi/18.0,3),\n",
    "                                                                               np.linspace(-np.pi/18.0,np.pi/18.0,3),\n",
    "                                                                               np.linspace(-10,10,3),\n",
    "                                                                               np.linspace(-10,10,3),\n",
    "                                                                               np.linspace(-10,10,3),\n",
    "                                                                               np.linspace(0.9,1.1,3))\n",
    "aug_transform = sitk.Similarity3DTransform()\n",
    "\n",
    "# Transform which maps from the reference_image to the current img with the translation mapping the image\n",
    "# origins to each other.\n",
    "transform = sitk.AffineTransform(dimension)\n",
    "transform.SetMatrix(img_sitk.GetDirection())\n",
    "transform.SetTranslation(np.array(img_sitk.GetOrigin()) - reference_origin)\n",
    "# Modify the transformation to align the centers of the original and reference image instead of their origins.\n",
    "centering_transform = sitk.TranslationTransform(dimension)\n",
    "img_center = np.array(img_sitk.TransformContinuousIndexToPhysicalPoint(np.array(img_sitk.GetSize())/2.0))\n",
    "centering_transform.SetOffset(np.array(transform.GetInverse().TransformPoint(img_center) - reference_center))\n",
    "centered_transform = sitk.Transform(transform)\n",
    "centered_transform.AddTransform(centering_transform)\n",
    "\n",
    "# Set the augmenting transform's center so that rotation is around the image center.\n",
    "aug_transform.SetCenter(reference_center)\n",
    "\n",
    "generated_image = augment_images_spatial(img_sitk, reference_image, centered_transform, \n",
    "                                       aug_transform, transformation_parameters_list, \n",
    "                                       os.path.join('./', 'spatial_aug_'), 'mha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sitk.sitkNearestNeighbor for labels!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (envGUT)",
   "language": "python",
   "name": "envgut"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
